{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca87c6b",
   "metadata": {},
   "source": [
    "üìì MLflow Scorers ‚Äî Fully Self-Contained Jupyter Notebook (Basic Auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec72427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0. Imports\n",
    "# ============================================================\n",
    "import os\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from mlflow.genai.scorers import scorer\n",
    "from mlflow.entities import Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd95fa",
   "metadata": {},
   "source": [
    "üîê 1. Configure MLflow Tracking + Basic Auth (Notebook-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b3773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/24', creation_time=1767983770216, experiment_id='24', last_update_time=1767983770216, lifecycle_stage='active', name='scorers-notebook-test', tags={'mlflow.experimentKind': 'genai_development'}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. MLflow tracking server configuration\n",
    "# ============================================================\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:8080\"\n",
    "MLFLOW_USERNAME = \"frank@example.com\"\n",
    "MLFLOW_PASSWORD = \"\"\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = MLFLOW_USERNAME\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = MLFLOW_PASSWORD\n",
    "\n",
    "# Optional but useful\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"scorers-notebook-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d3f16",
   "metadata": {},
   "source": [
    "‚úÖ 2. Sanity Check: Auth Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8995fb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auth OK, run ID: 97d1b604a43c4d019c6fc717c9ae95e0\n",
      "üèÉ View run auth-check at: http://localhost:8080/#/experiments/24/runs/97d1b604a43c4d019c6fc717c9ae95e0\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/24\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2. Auth sanity check\n",
    "# ============================================================\n",
    "\n",
    "with mlflow.start_run(run_name=\"auth-check\") as run:\n",
    "    mlflow.log_metric(\"auth_ok\", 1.0)\n",
    "    print(\"Auth OK, run ID:\", run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e42fb2",
   "metadata": {},
   "source": [
    "üß† 3. Define Dummy Custom Scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3dc0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. Custom scorers\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "@scorer\n",
    "def response_length(outputs: dict) -> Feedback:\n",
    "    text = outputs.get(\"response\", \"\")\n",
    "    length = len(text)\n",
    "    return Feedback(\n",
    "        value=length,\n",
    "        rationale=f\"Response length = {length}\",\n",
    "        metadata={\"chars\": length},\n",
    "    )\n",
    "\n",
    "\n",
    "@scorer\n",
    "def contains_hello(outputs: dict) -> Feedback:\n",
    "    text = outputs.get(\"response\", \"\").lower()\n",
    "    found = \"hello\" in text\n",
    "    return Feedback(\n",
    "        value=found,\n",
    "        rationale=f\"'hello' present: {found}\",\n",
    "        metadata={},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca481be",
   "metadata": {},
   "source": [
    "üìä 4. Create Dummy Evaluation Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a6aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. Dummy evaluation dataset\n",
    "# ============================================================\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"inputs\": {\"prompt\": \"Explain MLflow\"},\n",
    "            \"outputs\": {\"response\": \"Hello! MLflow helps track experiments.\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"prompt\": \"2 + 2\"},\n",
    "            \"outputs\": {\"response\": \"The answer is 4.\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"prompt\": \"Say hello\"},\n",
    "            \"outputs\": {\"response\": \"hello world\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"prompt\": \"Check scoring\"},\n",
    "            \"outputs\": {\"response\": \"code scoring example\"},\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd15e9",
   "metadata": {},
   "source": [
    "üß™ 5. Run MLflow GenAI Evaluation (Scorers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "761954fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <title>Evaluation output</title>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "        }\n",
       "\n",
       "        .header {\n",
       "            a.button {\n",
       "                padding: 4px 8px;\n",
       "                line-height: 20px;\n",
       "                box-shadow: none;\n",
       "                height: 20px;\n",
       "                display: inline-flex;\n",
       "                align-items: center;\n",
       "                justify-content: center;\n",
       "                vertical-align: middle;\n",
       "                background-color: rgb(34, 114, 180);\n",
       "                color: rgb(255, 255, 255);\n",
       "                text-decoration: none;\n",
       "                animation-duration: 0s;\n",
       "                transition: none 0s ease 0s;\n",
       "                position: relative;\n",
       "                white-space: nowrap;\n",
       "                text-align: center;\n",
       "                border: 1px solid rgb(192, 205, 216);\n",
       "                cursor: pointer;\n",
       "                user-select: none;\n",
       "                touch-action: manipulation;\n",
       "                border-radius: 4px;\n",
       "                gap: 6px;\n",
       "            }\n",
       "\n",
       "            a.button:hover {\n",
       "                background-color: rgb(14, 83, 139) !important;\n",
       "                border-color: transparent !important;\n",
       "                color: rgb(255, 255, 255) !important;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .warnings-section {\n",
       "            margin-top: 8px;\n",
       "\n",
       "            ul {\n",
       "                list-style-type: none;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .instructions-section {\n",
       "            margin-top: 16px;\n",
       "            font-size: 14px;\n",
       "\n",
       "            ul {\n",
       "                margin-top: 0;\n",
       "                margin-bottom: 0;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        code {\n",
       "            font-family: monospace;\n",
       "        }\n",
       "\n",
       "        .note {\n",
       "            color: #666;\n",
       "        }\n",
       "\n",
       "        a {\n",
       "            color: #2272B4;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "\n",
       "        a:hover {\n",
       "            color: #005580;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "    <div class=\"header\">\n",
       "        <a href=\"http://localhost:8080/#/experiments/24/evaluation-runs?selectedRunUuid=b4aef6ec15374b58b9be0742f0a36247\" class=\"button\">\n",
       "            View evaluation results in MLflow\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1em\" height=\"1em\" fill=\"none\" viewBox=\"0 0 16 16\" aria-hidden=\"true\" focusable=\"false\" class=\"\">\n",
       "                <path fill=\"currentColor\" d=\"M10 1h5v5h-1.5V3.56L8.53 8.53 7.47 7.47l4.97-4.97H10z\"></path>\n",
       "                <path fill=\"currentColor\" d=\"M1 2.75A.75.75 0 0 1 1.75 2H8v1.5H2.5v10h10V8H14v6.25a.75.75 0 0 1-.75.75H1.75a.75.75 0 0 1-.75-.75z\"></path>\n",
       "            </svg>\n",
       "        </a>\n",
       "    </div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged metrics:\n",
      "  response_length/mean: 21.25\n",
      "  contains_hello/mean: 0.5\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5. Run evaluation with scorers\n",
    "# ============================================================\n",
    "\n",
    "with mlflow.start_run(run_name=\"scorers-eval\"):\n",
    "    result = mlflow.genai.evaluate(\n",
    "        data=df,\n",
    "        scorers=[\n",
    "            response_length,\n",
    "            contains_hello,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "print(\"Logged metrics:\")\n",
    "for k, v in result.metrics.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
